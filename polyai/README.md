# PolyAI - Offline Multi-Agent AI Summarization System

An offline, privacy-preserving AI summarization engine that uses multi-agent debate architecture to deliver high-quality summaries without internet or cloud dependencies.

## ðŸŒŸ Key Features

- **100% Offline**: No internet required, complete privacy
- **< 10 MB Footprint**: Lightweight rule-based heuristics
- **Multi-Agent Debate**: 4 specialized agents collaborate for better results
- **Fast**: < 2 second latency on typical hardware
- **Privacy-First**: All processing happens locally

## ðŸ—ï¸ Architecture

```
[ Frontend (Web UI) ]
        â†“
[ Local API (FastAPI) ]
        â†“
[ PolyAI Core Engine ]
        â†“
[ Multi-Agent Debate System ]
        â†“
[ Final Refined Summary ]
```

### The Four Agents

1. **Reasoning Agent** ðŸ§  - Extracts key ideas and builds logical flow
2. **Verification Agent** âœ“ - Validates claims against source text
3. **Simplification Agent** ðŸ“ - Improves readability and clarity
4. **Critique Agent** ðŸ” - Finds gaps and quality issues

## ðŸš€ Quick Start

### Backend Setup

```powershell
cd polyai/backend

# Install dependencies
pip install -r requirements.txt

# Start the server
uvicorn main:app --reload --port 8000
```

### Frontend Setup

Simply open `polyai/frontend/index.html` in your browser.

The frontend can work:
- **With backend**: Full multi-agent processing via API
- **Standalone**: Uses built-in JavaScript fallback processing

## ðŸ“ Project Structure

```
polyai/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html      # Web interface
â”‚   â”œâ”€â”€ styles.css      # Modern dark theme
â”‚   â””â”€â”€ app.js          # UI logic + fallback processing
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py         # FastAPI server
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ core/
â”‚       â”œâ”€â”€ input_processor.py    # Text normalization
â”‚       â”œâ”€â”€ shared_encoder.py     # TF-IDF encoding
â”‚       â”œâ”€â”€ debate_engine.py      # Agent orchestration
â”‚       â”œâ”€â”€ scoring_engine.py     # Quality metrics
â”‚       â”œâ”€â”€ output_refiner.py     # Final polish
â”‚       â””â”€â”€ agents/
â”‚           â”œâ”€â”€ reasoning_agent.py
â”‚           â”œâ”€â”€ verification_agent.py
â”‚           â”œâ”€â”€ simplification_agent.py
â”‚           â””â”€â”€ critique_agent.py
â”‚
â””â”€â”€ README.md
```

## ðŸ”§ API Reference

### POST /summarize

```json
Request:
{
  "text": "Your long text to summarize...",
  "debug": false,
  "max_length": 500
}

Response:
{
  "summary": "The condensed summary...",
  "stats": {
    "original_words": 500,
    "summary_words": 100,
    "compression_percent": 80,
    "latency_ms": 450
  },
  "agents": { ... }  // Only if debug=true
}
```

### GET /health

Returns service health status and component readiness.

## ðŸŽ¨ UI Features

- **Dark Mode**: Modern glassmorphism design
- **Debug Mode**: View individual agent reasoning
- **Real-time Stats**: Word count, compression ratio, latency
- **Paste & Copy**: Quick clipboard integration

## ðŸ’¡ How It Works

1. **Input Processing**: Text is normalized, cleaned, and tokenized
2. **Shared Encoding**: TF-IDF vectorization creates text representation
3. **Agent Execution**: All 4 agents analyze the text independently
4. **Debate & Scoring**: Outputs are scored on coverage, clarity, brevity
5. **Output Refinement**: Best elements are merged and polished

The key insight: **Collective reasoning > model size**

Instead of one large model, multiple small specialized "experts" collaborate to produce better results than any single agent alone.

## ðŸ“Š Performance

| Metric | Target | Achieved |
|--------|--------|----------|
| Total Size | < 10 MB | âœ“ Pure Python/JS |
| Latency | < 2 sec | ~500ms typical |
| RAM Usage | < 2 GB | ~50MB |
| CPU Cores | 2 | Works on single core |

## ðŸ”’ Privacy

- **Zero data collection**: No telemetry or analytics
- **No external calls**: Works completely offline
- **Local storage only**: All processing on-device
- **Open source**: Fully auditable code

## ðŸ“ License

MIT License - Use freely for personal and commercial projects.
